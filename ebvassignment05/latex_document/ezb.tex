\documentclass{ezb}
\usepackage[]{todonotes}
\usepackage{amsmath}
\usepackage{gensymb}
\usepackage{wrapfig}
\usepackage{longtable}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage[colorlinks,        	% Links ohne Umrandungen in zu wählender Farbe
   linkcolor=black,   			% Farbe interner Verweise
   filecolor=black,   			% Farbe externer Verweise
   citecolor=black    			% Farbe von Zitaten
]{hyperref}
\usepackage{booktabs}

\renewcommand{\thesubsection}{\alph{subsection}}
\begin{document}

% \maketitle{Nummer}{Abgabedatum}{Tutor-Name}{Gruppennummer}
%           {Teilnehmer 1}{Teilnehmer 2}{Teilnehmer 3}
\maketitle{10.07.15}{Udo Frese}{1}{Annika Ofenloch - 2992807 - ofenloch@uni-bremen.de}{Frank Ihle - 3010158 - fihle@uni-bremen.de}{Simon Schirrmacher - 4000884 - simons@informatik.uni-bremen.de}{Noshaba Cheema - ncheema@uni-bremen.de}

%-------Text-Start------------------------------------------
\section{Harte Kante auf der Grafikkarte}
\begin{lstlisting}[language=C++]

__global__ void sobelKernel (uchar* dstImg, uchar* srcImg, int rows, int cols)
{
    //TODO: implement the sobel operator (6P)
	unsigned int x = blockDim.x * blockIdx.x + threadIdx.x;
	unsigned int y = blockDim.y * blockIdx.y + threadIdx.y;
	unsigned int step = gridDim.x * blockDim.x; 
	
	double sX = 0, sY = 0;
	
	if(in_img(x-1,y-1,rows,cols) && in_img(x+1,y+1,rows,cols)) {
		// (x,y) = step * y + x
		sX = (-srcImg[step * (y - 1) + x - 1] - 2 * srcImg[step * y + x - 1] - srcImg[step * (y + 1) + x - 1]
			 + srcImg[step * (y - 1) + x + 1] + 2 * srcImg[step * y + x + 1] + srcImg[step * (y + 1) + x + 1]) * 0.125;
			 
		sY = (-srcImg[step * (y - 1) + x - 1] - 2 * srcImg[step * (y - 1) + x] - srcImg[step * (y - 1) + x + 1]
			 + srcImg[step * (y + 1) + x - 1] + 2 * srcImg[step * (y + 1) + x] + srcImg[step * (y + 1) + x + 1]) * 0.125;
	}
	
	// save sobel length in image
	if(in_img(x,y,rows,cols))
		dstImg[step * y + x] = sqrt(sX * sX + sY * sY);
}

\end{lstlisting}
\begin{lstlisting}[language=C++]
void sobel (Mat_<uchar>& dstImg, const Mat_<uchar>& srcImg)
{
    //TODO: implement (4P)
	
	unsigned int data_length = dstImg.rows * dstImg.cols;
	size_t size = data_length * sizeof(uchar);
	
	uchar *gpuSrcImg, *gpuDstImg;
	
	// allocate memory for the images
	CHECK_CUDA(cudaMalloc((void**) &gpuSrcImg, size));
	CHECK_CUDA(cudaMalloc((void**) &gpuDstImg, size));
	
	// transfer the initialized source image to the device
	CHECK_CUDA(cudaMemcpy(gpuSrcImg, srcImg.data, size, cudaMemcpyHostToDevice));
	
	dim3 threads(16, 16);
	dim3 blocks(round_up(dstImg.cols, threads.x), round_up(dstImg.rows, threads.y));
	
	sobelKernel<<<blocks, threads>>>(gpuDstImg, gpuSrcImg, srcImg.rows, srcImg.cols);
	
	// copy results back to the host (implies cudaDeviceSynchronize())
	CHECK_CUDA(cudaMemcpy(dstImg.data, gpuDstImg, size, cudaMemcpyDeviceToHost));
	
	// free the memory
	CHECK_CUDA(cudaFree(gpuSrcImg));
	CHECK_CUDA(cudaFree(gpuDstImg));
	
	CHECK_CUDA(cudaDeviceReset());
}

\end{lstlisting}
\section{Schwarz und Weiß wir stehen an Eurer Seite}
Zu beginn des Spieles und bei jeder Unterbrechung werden die Roboter auf der Seite, welche ihrer Mannschaft entspricht aufgestellt, wodurch die Zuordnung der Roboter zu den beiden Mannschaften erfolgt.\\
\linebreak
\todo[inline]{was passiert bei (Freistoß,Anspiel nach einem Tor, Elfmeter, Faul, etc.) mit dem Filter?}
Um jeden einzelnen Roboter zu verfolgen, wird für jeden Roboter ein unabhängiger Partikelfilter eingesetzt.
Für diese Filter ist die reale Position, die Geschwindigkeit und deren Richtung als Vektor des Roboters und die Gewichtung des Zustandes der Zustandsraum. Die Dynamikfuntion bildet mit Hilfe des vorherigen Zustands und den Fahrkommandos jedes einzelnen Roboters als Vektor einen neuen Zustand. Die Messfunktion gewichtet die einzelnen Zustände (Partikel) im Zustandsraum, wofür die Position des Roboters im Bild herangezogen wird.\\
\linebreak
Hierbei gehen wir davon aus, dass äußere Einflüsse, z.B. Kontakt mit anderen Robotern, welche die Position des Roboters beeinflussen, so gering und zufällig sind, dass diese als Messrauschen nicht weiter beachtet werden müssen.\\
\linebreak
Sollte es dazu kommen, dass ein Roboter nicht mehr im Bild erfasst werden können (z.B. umgekippt oder außerahlb des Spielfeldes), wird der Partikelfilter neu initialisiert, sobald der Roboter wieder erfasst wird. Dieses Vorgehen funktioniert nur, wenn nur ein Roboter zur Zeit nicht mehr erfassbar ist. Sobald mehr als ein Roboter nicht mehr erfassbar ist, ist es nicht mehr möglich diese zu unterscheiden, wenn sie wieder im Bild erfasst werden.\\
\linebreak
Der Ball kann eindeutig von den Kreisen auf den Robotern unterschieden werden, da er nicht vor schwarzen Hintergrund liegt (hier nehmen wir an, dass die Spielfläche nicht schwarz ist). Mit diesen Voraussetzungen lässt sich der Ball genau wie die Billardkugel aus der Vorlesung verfolgen.\\
\linebreak
Über den Ball haben wir keine dynamischen Informationen, weshalb die Geschwindigkeit des Balls anhand der Positionen im Bild ermittelt wird, indem die zurückgelegte Strecken zwischen den Bildern berechnet wird. Nach einigen Einzelbildern können wir nun aus den Daten eine Dynamikfuntion herleiten, indem wir die Geschwindigkeit proportional zur Reibungskraft ändern.\\
\linebreak
Sollte der Ball nicht mehr im Bild zu erkennen sein, da er aus dem Bildbereich gefolgen ist oder sich direkt über einem Roboter befindet und nicht von der Markierung des Roboters unterschieden werden kann, wird der Partikelfilter neu initialisiert, sobald der ball wieder erfasst wurde. Dies ist ohne Weiteres möglich, da der Ball im Normalfall immer eindeutig identifiziert werden kann.
\section{Hinterm Horizont gehts weiter}
Die Kamera nimmt von einem Flugzeug aus die Landebahn auf, wie es in Abbildung \ref{} dargestellt ist. Hierbei erkennt das Bildverarbeitungssystem zwei Geraden, die die Landebahn bilden und parallel zueinander liegen. Der Abstand zwischen den Geraden ist bekannt. Die Kamera hat einen schrägen Blickwinkel auf die Landebahn, da ansonsten keine Landebahn im Blickfeld der Kamera wäre. Es ist demnach ein Fluchtpunkt vorhanden, der sich ermitteln lässt, indem der Schnittpunkt der Geraden ermittelt wird. Ein Fluchtpunkt kann sich hierbei auch außerhalb des Bildes befinden. Es müssen lediglich die Geraden vorhanden sein.

Eine Kamera verfügt über sechs Freiheitsgerade – die Translation in x-, y- und z-Richtung sowie die Rotation um die x mit dem Winkel $\alpha$, y mit dem Winkel $\beta$ und z Achse mit dem Winkel $\gamma$. Diese Kameraparameter beschreiben die Verschiebung  der Kamera zum Ursprung des Weltkoodinatensystems und die Drehung um die drei Euler Winkel. Es gibt jedoch einen Freiheitsgrad, der nicht beobachtet werden kann – die Translation in y-Richtung, wie es in den beiden Abbildungen \ref{} und \ref{} zu sehen ist. Dies liegt daran, dass sich die Geraden (Landebahn) auf der Bodenebene (X,Y) liegen.

% siehe Ansatz zur Posenbestimmung: http://userpages.uni-koblenz.de/~cg/Diplomarbeiten/DA_BernhardReinert.pdf

%-------Text-End------------------------------------------
\end{document}

